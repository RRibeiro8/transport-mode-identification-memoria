,idx model,Model,Classes,size,perplexity,Train,Accuracy,F1-Score,Epochs
0,0,ViT,5,64,50,92.19286460665771,92.71641791044776,89.74616485759617,116
1,1,ViT,5,64,50,93.77519032691447,92.53731343283582,88.33657683691797,160
2,2,ViT,5,64,50,93.14823107926556,92.53731343283582,88.54094228669844,191
3,3,ViT,5,64,50,92.34214061800269,92.77611940298507,88.99177333287858,120
4,4,ViT,5,64,50,92.61083743842364,92.35820895522389,88.71008174958742,149
5,5,ViT,5,64,50,90.99865651589789,92.65671641791045,89.27188645301932,91
6,6,ViT,5,64,50,91.71518137035379,92.59701492537313,88.31399227326337,101
7,7,ViT,5,64,50,92.32721301686819,92.23880597014926,87.32273681980877,153
8,8,ViT,5,64,50,94.26780116435289,92.53731343283582,89.6659077060118,186
9,9,ViT,5,64,50,91.81967457829526,92.35820895522389,89.30727330546176,74
10,10,ViT,5,64,50,93.47663830422451,92.53731343283582,89.51429661990254,152
11,11,ViT,5,64,50,92.11822660098522,92.11940298507463,88.33185032429182,113
12,12,ViT,5,64,50,92.99895506792059,92.4776119402985,88.86706569289865,176
13,13,ViT,5,64,50,92.98402746678609,92.59701492537313,89.85099668550993,140
14,14,ViT,5,64,50,92.98402746678609,92.59701492537313,87.7523925146396,143
15,15,ViT,5,64,50,91.43155694879833,92.11940298507463,88.0338775283947,72
16,16,ViT,5,64,50,91.43155694879833,92.35820895522389,88.76965390618275,83
17,17,ViT,5,64,50,91.43155694879833,92.35820895522389,88.30435890357266,87
18,18,ViT,5,64,50,94.40214957456337,92.4776119402985,89.05565926982366,215
19,19,ViT,5,64,50,91.74503657262278,92.29850746268657,87.82803675891125,99
